✅ 1️⃣ 클러스터링이 뭐야?
👉 비슷한 것끼리 그룹으로 나누는 것!

색연필을 색깔별로 나누기

친구들을 운동 좋아하는 친구, 게임 좋아하는 친구로 나누기

✅ 왜 해?

복잡한 걸 정리하고 쉽게 이해하려고!

✅ 2️⃣ 차원(치수)이 뭐야?
👉 **정보가 들어있는 줄(특성)**이라고 생각하면 돼!

예:

사람 정보 → 나이, 키, 몸무게 → 3차원

얼굴 사진 → 눈, 코, 입, 피부색 등 → 수백 개 정보 = 수백 차원

✅ 차원이 많으면?

컴퓨터가 계산하기 힘들어

그림으로 보기 힘들어

데이터가 “엉성”해져서 그룹 나누기 어려워져

✅ 3️⃣ 차원 축소가 뭐야?
👉 중요한 정보만 남기고 줄이는 것!

✅ 예:

색연필 100자루에서

너무 비슷한 색 → 대표 색 하나로 줄이기

✅ 데이터에서는:

100개 정보 중에서 → 진짜 중요한 2~3개만 남기기

✅ 왜 필요해?

계산이 빨라짐

그림으로 쉽게 볼 수 있음 (2D/3D로!)

중요한 정보만 남겨서 더 잘 맞힐 수 있음

✅ 차원 축소 방법 예시
📌 PCA

중요 정보 순서대로 정리 → 제일 중요한 축으로 줄임

얼굴 사진 → “주요 얼굴 특징(고유면)”만 남기기

📌 T-SNE, UMAP

복잡한 모양을 → 2D/3D로 예쁘게 펼치기

그림으로 보기 좋게

✅ 4️⃣ 클러스터링이랑 차원 축소는 어떻게 같이 쓰나?
👉 차원 축소 → 클러스터링 쉽게 만들기!

✅ 이유:

차원이 너무 크면 → 그룹 나누기 어려움

차원을 줄이면 → 잘 모인 그룹이 보임

✅ 예:

얼굴 사진 1000장 → 정보가 너무 많음

차원 축소 → 중요한 150개 특징만!

→ 클러스터링이 가능해짐

✅ 5️⃣ 얼굴 인식 예시!
얼굴 사진 데이터 → 너무 정보가 많아

PCA로 → 중요한 얼굴 특징 150개만 남김

이 특징을 보고 → 누구 얼굴인지 맞히는 모델 학습

결과 → 정확하게 사람 구별 가능!

✅ 이게 차원 축소가 얼굴 인식에 쓰이는 방법이야.

✅ 6️⃣ 클러스터링으로 특징 선택을 돕는 방법
👉 비슷한 특성(정보)을 찾아서 하나로 줄이기

✅ 예:

시험 점수

국어, 독서 → 너무 비슷해!

하나만 써도 될 수도 있어

✅ 컴퓨터에서는:

여러 개 정보가 비슷하면

클러스터링으로 묶기

대표 하나만 쓰기 → 모델이 더 간단하고 좋아짐

✅ 데이터 예시

5개의 특성(정보)이 있어

특성 1, 2, 3 → 값이 비슷해 → 같은 그룹!

특성 4, 5 → 다른 그룹!

k-평균으로 클러스터링

그룹별로 대표 특성만 선택

✅ 7️⃣ 왜 이걸 해?
✅ 모델을 더 좋게 만들려고!

계산 빨라짐

과적합 줄임 (필요 없는 정보 버리니까!)

해석하기 쉬워짐

중요한 정보만 남겨서 더 정확해짐

✅ 8️⃣ 세 가지 개념 정리
✨ 클러스터링

비슷한 것끼리 묶기

예: 친구들 취미별로 나누기

✨ 차원 축소

중요한 정보만 남기고 줄이기

예: 색연필 100색 → 대표 색 5개로 줄이기

✨ 특징 엔지니어링

데이터를 더 좋게 바꾸기

필요 없는 정보 제거

새로운 유용한 정보 만들기

✅ 이 셋이 함께 쓰이면?
👉 훨씬 똑똑하고 좋은 모델을 만들 수 있어!

✅ 예:

차원 축소 → 정보 줄이기

클러스터링 → 비슷한 것끼리 묶기

특징 선택 → 필요 없는 거 빼고 중요한 것만 쓰기

✅ 초간단 한 문장 요약!

비슷한 것끼리 묶고, 중요한 것만 남겨서, 모델이 더 똑똑하게 예측하게 하는 기술!