💡 K-NN이 뭐야? K-Nearst Neighbors
👉 K-NN(케이 최근접 이웃)은 “비슷한 걸 보고 맞히는 방법” 이야.
👉 컴퓨터가 “이게 뭐야?” 하고 맞히도록 도와주는 방법 중 하나야!

✅ 아주 간단한 예시
학교 운동장에서 축구공이랑 농구공이 섞여 있어.

새 공이 하나 나왔을 때 “이게 축구공이야? 농구공이야?” 맞혀야 해.

✅ 어떻게 할까?
👉 주변 공들을 보고 결정해!

주변에 축구공이 많으면 “이건 축구공이야!”
주변에 농구공이 많으면 “이건 농구공이야!”

✅ K가 뭐야?
K는 **“주변 몇 개를 볼지”**를 정하는 숫자야!

K=3 → 제일 가까운 3개를 보고 다수결로 결정
K=5 → 제일 가까운 5개를 보고 다수결

✅ 어떻게 작동하냐면?
1️⃣ 컴퓨터가 새 공(새 데이터)을 본다.
2️⃣ 저장해 둔 예제들(이게 축구공인지 농구공인지 정답이 붙은 데이터)을 꺼낸다.
3️⃣ 새 공과 저장된 공들 사이의 거리를 잰다.
4️⃣ 제일 가까운 K개를 고른다.
5️⃣ 다수결 투표를 한다.

축구공이 2개, 농구공이 1개 → “축구공!”

✅ 회귀일 때는?
👉 정답이 “숫자”인 문제라면

주변 K개의 숫자를 평균 내서 예측해!

예:주변 집 값이 5억, 5.5억, 6억이면?
 ≈ 5.5억으로 예측!

✅ K가 너무 작으면?
너무 민감해져서 “헷갈리기” 좋아!

예: 주변 1개만 보면 이상한 예제에 끌릴 수 있어 → 과적합이라고 해.

✅ K가 너무 크면?
너무 둥글둥글해져서 “대충 맞히는” 느낌!

디테일이 없어짐 → 과소적합이라고 해.

✅ 그래서 K는 적당한 숫자를 찾아야 해!

보통 여러 값을 시도해보고 정확도가 가장 좋은 K를 고른다.

✅ 특징이 뭐야?
컴퓨터가 비교할 때 쓰는 정보야!

예: 꽃 → 꽃잎 길이, 꽃잎 너비
공 → 크기, 색깔

👉 좋은 특징만 쓰면 정확도가 좋아져!

✅ 거리란?
컴퓨터가 “얼마나 비슷한지”를 재는 방법 
가까울수록 비슷하다 생각해

✅ K-NN의 장점
간단해!
설명하기 쉽고 이해하기 좋아!
데이터가 많으면 성능이 좋아질 수 있어!

✅ K-NN의 단점
새 거 맞힐 때 계산이 느릴 수 있어 → 전부 거리 재야 하니까
특성이 많거나 이상한 정보가 섞이면 헷갈릴 수 있어
정보의 중요도를 잘 모름!

K를 잘 골라야 해!

✅ K-NN이 쓰이는 곳
사진 보고 동물 맞히기
손글씨 숫자 읽기
추천 시스템
환자 병 진단

✅ 아주 간단하게 정리!

“K-NN은 ‘가까운 친구들을 보고 나도 같은 거라고 생각하는’ 방법이야!”