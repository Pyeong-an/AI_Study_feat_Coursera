✅ 1️⃣ 비지도 학습(unsupervised learning)이 뭐야?
👉 정답이 없는 데이터를 스스로 분류하거나 요약하는 것!

✅ 예:

친구들 취미로 그룹 나누기 → 누가 운동 좋아하는지 직접 알려주지 않음!

색연필을 색깔별로 자동으로 나누기

✅ 2️⃣ 평가가 왜 필요해?
👉 "잘 나눴는지" 확인해야 하니까!

✅ 문제는?

정답이 없어서 → 맞았는지 직접 비교하기 어려움!

그래서 “얼마나 잘 나눈 것 같아 보이는지” → 여러 가지 방법으로 평가

✅ 3️⃣ 비지도 학습 평가의 3가지 큰 관점
✅ ① 내부 평가 (Internal Metrics)

데이터를 보고 스스로 평가

“이 그룹이 얼마나 잘 뭉쳤나?”

✅ ② 외부 평가 (External Metrics)

정답 라벨이 있으면 → 비교

“진짜 그룹이랑 얼마나 비슷해?”

✅ ③ 안정성 / 일반화 (Stability)

데이터가 살짝 달라져도 → 비슷하게 나누는지 확인

“변해도 결과가 비슷해야 믿을 수 있어!”

✅ 4️⃣ 내부 평가 지표 (Internal Metrics)
⭐️ Silhouette Score
✅ 무엇?

한 그룹 안에서 얼마나 가까이 모였나?

다른 그룹과 얼마나 멀리 떨어졌나?

✅ 값

-1 ~ +1 사이

높을수록 → 그룹이 잘 나눠짐

✅ 장점
✔️ 직관적
✔️ 값 하나로 평가 가능

✅ 단점
✘ 복잡한 모양(비선형 클러스터)에는 부정확

✅ 비유

반 친구들끼리 앉을 때

친한 애들끼리 모여 앉았나?

다른 무리랑 떨어졌나?

⭐️ Davies-Bouldin Index
✅ 무엇?

각 그룹이 얼마나 조밀한지(Compactness)

그리고 다른 그룹과 얼마나 떨어졌는지(Separation) 비교

✅ 값

0 이상

낮을수록 좋음! → 그룹 간 구별이 잘됨

✅ 장점
✔️ 여러 그룹 간 비교 좋아

✅ 단점
✘ 해석이 조금 어려움
✘ 이상치 영향 받음

✅ 비유

각 무리가 얼마나 단단히 모였나 + 서로 얼마나 멀리 떨어졌나 측정

⭐️ Inertia (for K-Means)
✅ 무엇?

그룹 안에서 각 점이 중심과 얼마나 가까운지 합

✅ 값

0 이상

낮을수록 그룹이 잘 뭉침

✅ 장점
✔️ K-means에서 간단하게 계산

✅ 단점
✘ K가 커지면 무조건 작아짐 → 너무 세분화 가능

✅ 비유

무리 중심으로 얼마나 빽빽하게 모였나 측정

✅ 5️⃣ 외부 평가 지표 (External Metrics)
✅ 라벨(정답)이 있을 때 → 비교 가능

⭐️ Adjusted Rand Index (ARI)
✅ 무엇?

클러스터와 실제 라벨이 얼마나 비슷한지

랜덤한 군집화와 비교

✅ 값

-1 ~ 1

1 → 완벽하게 같음

0 → 랜덤

음수 → 랜덤보다 못함

✅ 장점
✔️ 랜덤 결과 보정
✔️ 해석 쉬움

✅ 단점
✘ 라벨 필요

✅ 비유

친구가 만든 그룹이 선생님 기준이랑 얼마나 비슷한지!

⭐️ Normalized Mutual Information (NMI)
✅ 무엇?

클러스터와 실제 라벨이 공유하는 정보량

✅ 값

0 ~ 1

1 → 완벽 일치

✅ 장점
✔️ 그룹 수 달라도 비교 가능
✔️ 해석 직관적

✅ 단점
✘ 라벨 필요

✅ 비유

두 그룹 분류가 서로 얼마나 같은 정보를 담았나?

⭐️ Fowlkes-Mallows Index (FMI)
✅ 무엇?

클러스터링 → Precision과 Recall의 균형

✅ 값

0 ~ 1

1 → 완벽

✅ 장점
✔️ 직관적 → 정확도+재현율

✅ 단점
✘ 라벨 필요

✅ 비유

“친구들을 잘 맞게 나눈 비율”

✅ 6️⃣ 안정성 평가 (Stability / Generalizability)
✅ 무엇?

데이터가 조금 달라도 → 비슷하게 나누나?

“모델이 튼튼한지” 확인

✅ 장점
✔️ 실생활 데이터 변동 대비

✅ 단점
✘ 계산 비용 높음
✘ 기준 정의가 애매할 수 있음

✅ 비유

시험 문제 살짝 바꿔도 → 여전히 잘 푸는 친구

✅ 7️⃣ 차원축소 평가
✅ 차원축소 → 정보 줄여서 요약
→ 잘 줄였는지 평가 필요

⭐️ Explained Variance Ratio (PCA)
✅ 무엇?

얼마나 많은 정보를 남겼는지

높을수록 좋음

✅ 장점
✔️ 직관적
✔️ 정보 보존 확인

✅ 단점
✘ 선형 관계만 측정

⭐️ Reconstruction Error
✅ 무엇?

줄였다가 → 다시 복원할 때 오차

낮을수록 좋음

✅ 장점
✔️ 정보 손실 바로 측정

✅ 단점
✘ 계산 비용 높을 수 있음

⭐️ Neighborhood Preservation
✅ 무엇?

가까운 친구가 → 줄인 뒤에도 여전히 가까운지

특히 t-SNE, UMAP에 중요

✅ 장점
✔️ 구조 보존 확인

✅ 단점
✘ 정의 방식 다양 → 해석 주의

✅ 8️⃣ 평가할 때 중요한 팁
✅ 정답이 없는 문제 → “하나만” 보면 안 돼!
✅ 여러 지표를 같이 보고
✅ 눈으로 시각화 → Scatter plot, Dendrogram
✅ 전문가 의견 → “이렇게 나눈 게 의미 있나?”

✅ 아주 간단 요약!
비지도 학습 평가는 정답이 없으니 다양한 방법으로 잘 나눴는지 확인하는 것!

내부 지표 → 데이터 자체만 보고 평가

외부 지표 → 정답 라벨과 비교

안정성 → 데이터 변해도 결과 유지?

차원축소 평가 → 정보 얼마나 잘 보존?